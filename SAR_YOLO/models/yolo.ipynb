{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-05T06:35:19.634133500Z",
     "start_time": "2024-06-05T06:35:05.732837600Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import contextlib\n",
    "import math\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from models.common import (\n",
    "    C3,\n",
    "    C3SPP,\n",
    "    C3TR,\n",
    "    SPP,\n",
    "    SPPF,\n",
    "    Bottleneck,\n",
    "    BottleneckCSP,\n",
    "    C3Ghost,\n",
    "    C3x,\n",
    "    Classify,\n",
    "    Concat,\n",
    "    Contract,\n",
    "    Conv,\n",
    "    CrossConv,\n",
    "    DetectMultiBackend,\n",
    "    DWConv,\n",
    "    DWConvTranspose2d,\n",
    "    Expand,\n",
    "    Focus,\n",
    "    GhostBottleneck,\n",
    "    GhostConv,\n",
    "    Proto,\n",
    ")\n",
    "from models.experimental import MixConv2d\n",
    "from utils.autoanchor import check_anchor_order\n",
    "from utils.general import LOGGER, check_version, check_yaml, colorstr, make_divisible, print_args\n",
    "from utils.plots import feature_visualization\n",
    "from utils.torch_utils import (\n",
    "    fuse_conv_and_bn,\n",
    "    initialize_weights,\n",
    "    model_info,\n",
    "    profile,\n",
    "    scale_img,\n",
    "    select_device,\n",
    "    time_sync,\n",
    ")\n",
    "\n",
    "try:\n",
    "    import thop  # for FLOPs computation\n",
    "except ImportError:\n",
    "    thop = None\n",
    "\n",
    "class Detect(nn.Module):\n",
    "    # YOLOv5 Detect head for detection models\n",
    "    stride = None  # strides computed during build\n",
    "    dynamic = False  # force grid reconstruction\n",
    "    export = False  # export mode\n",
    "\n",
    "    def __init__(self, nc=80, anchors=(), ch=(), inplace=True):\n",
    "        \"\"\"Initializes YOLOv5 detection layer with specified classes, anchors, channels, and inplace operations.\"\"\"\n",
    "        super().__init__()\n",
    "        self.nc = nc  # number of classes\n",
    "        self.no = nc + 5  # number of outputs per anchor\n",
    "        self.nl = len(anchors)  # number of detection layers\n",
    "        self.na = len(anchors[0]) // 2  # number of anchors\n",
    "        self.grid = [torch.empty(0) for _ in range(self.nl)]  # init grid\n",
    "        self.anchor_grid = [torch.empty(0) for _ in range(self.nl)]  # init anchor grid\n",
    "        self.register_buffer(\"anchors\", torch.tensor(anchors).float().view(self.nl, -1, 2))  # shape(nl,na,2)\n",
    "        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv\n",
    "        self.inplace = inplace  # use inplace ops (e.g. slice assignment)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Processes input through YOLOv5 layers, altering shape for detection: `x(bs, 3, ny, nx, 85)`.\"\"\"\n",
    "        z = []  # inference output\n",
    "        for i in range(self.nl):\n",
    "            x[i] = self.m[i](x[i])  # conv\n",
    "            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)\n",
    "            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n",
    "\n",
    "            if not self.training:  # inference\n",
    "                if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
    "                    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n",
    "\n",
    "                if isinstance(self, Segment):  # (boxes + masks)\n",
    "                    xy, wh, conf, mask = x[i].split((2, 2, self.nc + 1, self.no - self.nc - 5), 4)\n",
    "                    xy = (xy.sigmoid() * 2 + self.grid[i]) * self.stride[i]  # xy\n",
    "                    wh = (wh.sigmoid() * 2) ** 2 * self.anchor_grid[i]  # wh\n",
    "                    y = torch.cat((xy, wh, conf.sigmoid(), mask), 4)\n",
    "                else:  # Detect (boxes only)\n",
    "                    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n",
    "                    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n",
    "                    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh\n",
    "                    y = torch.cat((xy, wh, conf), 4)\n",
    "                z.append(y.view(bs, self.na * nx * ny, self.no))\n",
    "\n",
    "        return x if self.training else (torch.cat(z, 1),) if self.export else (torch.cat(z, 1), x)\n",
    "\n",
    "    def _make_grid(self, nx=20, ny=20, i=0, torch_1_10=check_version(torch.__version__, \"1.10.0\")):\n",
    "        \"\"\"Generates a mesh grid for anchor boxes with optional compatibility for torch versions < 1.10.\"\"\"\n",
    "        d = self.anchors[i].device\n",
    "        t = self.anchors[i].dtype\n",
    "        shape = 1, self.na, ny, nx, 2  # grid shape\n",
    "        y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)\n",
    "        yv, xv = torch.meshgrid(y, x, indexing=\"ij\") if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n",
    "        grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5\n",
    "        anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n",
    "        return grid, anchor_grid\n",
    "\n",
    "\n",
    "class Segment(Detect):\n",
    "    # YOLOv5 Segment head for segmentation models\n",
    "    def __init__(self, nc=80, anchors=(), nm=32, npr=256, ch=(), inplace=True):\n",
    "        \"\"\"Initializes YOLOv5 Segment head with options for mask count, protos, and channel adjustments.\"\"\"\n",
    "        super().__init__(nc, anchors, ch, inplace)\n",
    "        self.nm = nm  # number of masks\n",
    "        self.npr = npr  # number of protos\n",
    "        self.no = 5 + nc + self.nm  # number of outputs per anchor\n",
    "        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv\n",
    "        self.proto = Proto(ch[0], self.npr, self.nm)  # protos\n",
    "        self.detect = Detect.forward\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Processes input through the network, returning detections and prototypes; adjusts output based on\n",
    "        training/export mode.\n",
    "        \"\"\"\n",
    "        p = self.proto(x[0])\n",
    "        x = self.detect(self, x)\n",
    "        return (x, p) if self.training else (x[0], p) if self.export else (x[0], p, x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1m3592105272: \u001B[0mcfg=yolov5s.yaml, batch_size=1, device=, profile=False, line_profile=False, test=False\n",
      "YOLOv5  299d3d70 Python-3.8.18 torch-1.13.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3050 Laptop GPU, 4096MiB)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--cfg\", type=str, default=\"yolov5s.yaml\", help=\"model.yaml\")\n",
    "parser.add_argument(\"--batch-size\", type=int, default=1, help=\"total batch size for all GPUs\")\n",
    "parser.add_argument(\"--device\", default=\"\", help=\"cuda device, i.e. 0 or 0,1,2,3 or cpu\")\n",
    "parser.add_argument(\"--profile\", action=\"store_true\", help=\"profile model speed\")\n",
    "parser.add_argument(\"--line-profile\", action=\"store_true\", help=\"profile model speed layer by layer\")\n",
    "parser.add_argument(\"--test\", action=\"store_true\", help=\"test all yolo*.yaml\")\n",
    "opt = parser.parse_known_args()[0]\n",
    "opt.cfg = check_yaml(opt.cfg)  # check YAML\n",
    "print_args(vars(opt))\n",
    "\n",
    "device = select_device(opt.device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T06:35:21.444248300Z",
     "start_time": "2024-06-05T06:35:21.143539200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Read model.yaml"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class num: 6\n",
      "anchors: [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]\n",
      "backbone: [[-1, 1, 'Conv', [64, 6, 2, 2]], [-1, 1, 'Conv', [128, 3, 2]], [-1, 3, 'C3', [128]], [-1, 1, 'Conv', [256, 3, 2]], [-1, 6, 'C3', [256]], [-1, 1, 'Conv', [512, 3, 2]], [-1, 9, 'C3', [512]], [-1, 1, 'Conv', [1024, 3, 2]], [-1, 3, 'C3', [1024]], [-1, 1, 'SPPF', [1024, 5]]]\n",
      "head: [[-1, 1, 'Conv', [512, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 6], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [256, 1, 1]], [-1, 1, 'nn.Upsample', ['None', 2, 'nearest']], [[-1, 4], 1, 'Concat', [1]], [-1, 3, 'C3', [256, False]], [-1, 1, 'Conv', [256, 3, 2]], [[-1, 14], 1, 'Concat', [1]], [-1, 3, 'C3', [512, False]], [-1, 1, 'Conv', [512, 3, 2]], [[-1, 10], 1, 'Concat', [1]], [-1, 3, 'C3', [1024, False]], [[17, 20, 23], 1, 'Detect', ['nc', 'anchors']]]\n"
     ]
    }
   ],
   "source": [
    "cfg=\"yolov5s.yaml\"\n",
    "if isinstance(cfg, dict):\n",
    "    yaml = cfg  # model dict\n",
    "else:  # is *.yaml\n",
    "    import yaml  # for torch hub\n",
    "    from pathlib import Path\n",
    "    with open(cfg, encoding=\"ascii\", errors=\"ignore\") as f:\n",
    "        yaml = yaml.safe_load(f)  # model dict\n",
    "\n",
    "print('class num:', yaml['nc'])\n",
    "print('anchors:', yaml['anchors'])\n",
    "print('backbone:', yaml['backbone'])\n",
    "print('head:', yaml['head'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T06:35:29.199515300Z",
     "start_time": "2024-06-05T06:35:29.170618200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Set nc, anchors, ch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ch: [3] 默认值是3，代表RGB图像\n",
      "anchors: [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]\n"
     ]
    }
   ],
   "source": [
    "nc=None\n",
    "anchors=None\n",
    "#  这两行代码设置了输入通道数量(ch)。默认值是3，代表RGB图像。如果YAML文件中有定义，那么会使用文件中的值.\n",
    "ch=3  # classes, anchors, input channels\n",
    "ch = yaml[\"ch\"] = yaml.get(\"ch\", ch)  # input channels\n",
    "\n",
    "#  这两个判断语句检查是否需要覆盖类别数量和锚点的值。如果需要，那么就会用新的值覆盖YAML文件中的值。\n",
    "#  如果不指定nc和anchors，那么就会使用YAML文件中的值。\n",
    "if nc and nc != yaml[\"nc\"]:\n",
    "    LOGGER.info(f\"Overriding model.yaml nc={yaml['nc']} with nc={nc}\")\n",
    "    yaml[\"nc\"] = nc  # override yaml value\n",
    "if anchors:\n",
    "    LOGGER.info(f\"Overriding model.yaml anchors with anchors={anchors}\")\n",
    "    yaml[\"anchors\"] = round(anchors)  # override yaml value\n",
    "\n",
    "# deepcopy yaml，防止修改原始数据\n",
    "d = deepcopy(yaml)\n",
    "ch=[ch]\n",
    "print('ch:', ch, '默认值是3，代表RGB图像')\n",
    "\n",
    "anchors, nc, gd, gw, act, ch_mul = (\n",
    "    d[\"anchors\"],\n",
    "    d[\"nc\"],\n",
    "    d[\"depth_multiple\"],\n",
    "    d[\"width_multiple\"],\n",
    "    d.get(\"activation\"),\n",
    "    d.get(\"channel_multiple\"),\n",
    ")\n",
    "\n",
    "print('anchors:', anchors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T06:35:49.160597700Z",
     "start_time": "2024-06-05T06:35:49.147638400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Set default activation and channel_multiple\n",
    "`Conv.default_act = eval(act)`\n",
    "eval(act) 是一个Python内置函数，它会执行一个字符串形式的表达式，并返回结果。在这个例子中，act 是一个字符串，代表了激活函数的名称，比如 \"nn.SiLU()\"。eval(act) 会返回这个激活函数的实例，然后赋值给 Conv.default_act。\n",
    "在YOLOv5模型配置中，channel_multiple是一个可选参数，用于调整模型中每一层的通道数。这个参数可以用来控制模型的宽度。例如，如果channel_multiple设置为2，那么模型中每一层的通道数将会翻倍。这可以用来增加模型的复杂性和容量，可能会提高模型的性能，但同时也会增加模型的计算量和参数数量。如果没有在配置文件中指定channel_multiple，则默认值为8。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of anchors: 3\n",
      "number of outputs: 33 计算方式: [x,y,w,h,class]有5个参数, na个anchors, nc个Class\n"
     ]
    }
   ],
   "source": [
    "if act:\n",
    "    Conv.default_act = eval(act)  # redefine default activation, i.e. Conv.default_act = nn.SiLU()\n",
    "    LOGGER.info(f\"{colorstr('activation:')} {act}\")  # print\n",
    "if not ch_mul:\n",
    "    ch_mul = 8\n",
    "na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors\n",
    "print('number of anchors:', na)\n",
    "no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)\n",
    "print('number of outputs:', no, '计算方式:', '[x,y,w,h,class]有5个参数, na个anchors, nc个Class')\n",
    "\n",
    "# Initialization\n",
    "layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T06:36:03.193775400Z",
     "start_time": "2024-06-05T06:36:03.177730800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`eval(m)`\n",
    "表示将字符串m作为函数或类实现，大概是这样吧"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1    589888  models.common.Conv                      [512, 32, 6, 2, 2]            \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes from 1 to 5 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 55\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m     c2 \u001B[38;5;241m=\u001B[39m ch[f]\n\u001B[1;32m---> 55\u001B[0m m_ \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\u001B[38;5;241m*\u001B[39m(m(\u001B[38;5;241m*\u001B[39margs) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n))) \u001B[38;5;28;01mif\u001B[39;00m n \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[43mm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# module\u001B[39;00m\n\u001B[0;32m     56\u001B[0m t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(m)[\u001B[38;5;241m8\u001B[39m:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m]\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__.\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)  \u001B[38;5;66;03m# module type\u001B[39;00m\n\u001B[0;32m     57\u001B[0m np \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(x\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m m_\u001B[38;5;241m.\u001B[39mparameters())  \u001B[38;5;66;03m# number params\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() takes from 1 to 5 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "LOGGER.info(f\"\\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}\")\n",
    "for i, (f, n, m, args) in enumerate(d[\"backbone\"] + d[\"head\"]):  # from, number, module, args\n",
    "    m = eval(m) if isinstance(m, str) else m  # eval strings\n",
    "    for j, a in enumerate(args):\n",
    "        with contextlib.suppress(NameError):\n",
    "            args[j] = eval(a) if isinstance(a, str) else a  # eval strings\n",
    "\n",
    "    n = n_ = max(round(n * gd), 1) if n > 1 else n  # depth gain\n",
    "    if m in {\n",
    "        Conv,\n",
    "        GhostConv,\n",
    "        Bottleneck,\n",
    "        GhostBottleneck,\n",
    "        SPP,\n",
    "        SPPF,\n",
    "        DWConv,\n",
    "        MixConv2d,\n",
    "        Focus,\n",
    "        CrossConv,\n",
    "        BottleneckCSP,\n",
    "        C3,\n",
    "        C3TR,\n",
    "        C3SPP,\n",
    "        C3Ghost,\n",
    "        nn.ConvTranspose2d,\n",
    "        DWConvTranspose2d,\n",
    "        C3x,\n",
    "    }:\n",
    "        c1, c2 = ch[f], args[0]\n",
    "        if c2 != no:  # if not output\n",
    "            c2 = make_divisible(c2 * gw, ch_mul)\n",
    "\n",
    "        args = [c1, c2, *args[1:]]\n",
    "        if m in {BottleneckCSP, C3, C3TR, C3Ghost, C3x}:\n",
    "            args.insert(2, n)  # number of repeats\n",
    "            n = 1\n",
    "    elif m is nn.BatchNorm2d:\n",
    "        args = [ch[f]]\n",
    "    elif m is Concat:\n",
    "        c2 = sum(ch[x] for x in f)\n",
    "    # TODO: channel, gw, gd\n",
    "    elif m in {Detect, Segment}:\n",
    "        args.append([ch[x] for x in f])\n",
    "        if isinstance(args[1], int):  # number of anchors\n",
    "            args[1] = [list(range(args[1] * 2))] * len(f)\n",
    "        if m is Segment:\n",
    "            args[3] = make_divisible(args[3] * gw, ch_mul)\n",
    "    elif m is Contract:\n",
    "        c2 = ch[f] * args[0] ** 2\n",
    "    elif m is Expand:\n",
    "        c2 = ch[f] // args[0] ** 2\n",
    "    else:\n",
    "        c2 = ch[f]\n",
    "\n",
    "    m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # module\n",
    "    t = str(m)[8:-2].replace(\"__main__.\", \"\")  # module type\n",
    "    np = sum(x.numel() for x in m_.parameters())  # number params\n",
    "    m_.i, m_.f, m_.type, m_.np = i, f, t, np  # attach index, 'from' index, type, number params\n",
    "    LOGGER.info(f\"{i:>3}{str(f):>18}{n_:>3}{np:10.0f}  {t:<40}{str(args):<30}\")  # print\n",
    "    save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # append to savelist\n",
    "    layers.append(m_)\n",
    "    if i == 0:\n",
    "        ch = []\n",
    "    ch.append(c2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-05T06:37:23.507274600Z",
     "start_time": "2024-06-05T06:37:23.380664500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv(\n",
      "  (conv): Conv2d(3, 32, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n",
      "  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), Conv(\n",
      "  (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), Conv(\n",
      "  (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), Conv(\n",
      "  (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), Conv(\n",
      "  (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), SPPF(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "), Conv(\n",
      "  (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), Upsample(scale_factor=2.0, mode=nearest), Concat(), C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), Conv(\n",
      "  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), Upsample(scale_factor=2.0, mode=nearest), Concat(), C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), Conv(\n",
      "  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), Concat(), C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), Conv(\n",
      "  (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (act): SiLU()\n",
      "), Concat(), C3(\n",
      "  (cv1): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv2): Conv(\n",
      "    (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (cv3): Conv(\n",
      "    (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): SiLU()\n",
      "  )\n",
      "  (m): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "), Detect(\n",
      "  (m): ModuleList(\n",
      "    (0): Conv2d(128, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(512, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(*layers)  # model\n",
    "model.nc = nc  # attach number of classes to model\n",
    "# layers print\n",
    "print(layers)\n",
    "save = sorted(save)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:22:51.141308500Z",
     "start_time": "2024-05-09T09:22:51.083411600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "names: ['0', '1', '2', '3', '4', '5']\n"
     ]
    }
   ],
   "source": [
    "names = [str(i) for i in range(yaml[\"nc\"])]  # default names\n",
    "print('names:', names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:43:53.398491800Z",
     "start_time": "2024-05-09T09:43:53.390518500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inplace: True\n"
     ]
    }
   ],
   "source": [
    "inplace = yaml.get(\"inplace\", True)\n",
    "print('inplace:', inplace)\n",
    "# ，inplace 是一个布尔值，用于决定某些操作是否在原地进行。如果 inplace 为 True，则操作会直接修改数据，而不会创建新的数据或变量。这通常可以节省内存，但可能会覆盖原始数据，因此需要谨慎使用。如果 inplace 为 False，则操作会创建新的数据或变量，而不会修改原始数据。"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:46:06.993204900Z",
     "start_time": "2024-05-09T09:46:06.976266400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m: Detect(\n",
      "  (m): ModuleList(\n",
      "    (0): Conv2d(128, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): Conv2d(512, 33, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n",
      "nl: 3\n"
     ]
    }
   ],
   "source": [
    "m = model[-1]  # Detect()\n",
    "print('m:', m)\n",
    "nl = model[-1].nl  # number of detection layers (P3-P5)\n",
    "print('nl:', nl)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T09:50:07.199180200Z",
     "start_time": "2024-05-09T09:50:07.185225800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zeros(): argument 'size' must be tuple of SymInts, but found element of type list at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 22\u001B[0m\n\u001B[0;32m     20\u001B[0m m\u001B[38;5;241m.\u001B[39minplace \u001B[38;5;241m=\u001B[39m inplace\n\u001B[0;32m     21\u001B[0m forwa \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m x: forward(x)[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(m, Segment) \u001B[38;5;28;01melse\u001B[39;00m forward(x)\n\u001B[1;32m---> 22\u001B[0m m\u001B[38;5;241m.\u001B[39mstride \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([s \u001B[38;5;241m/\u001B[39m x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m forwa(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzeros\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms\u001B[49m\u001B[43m)\u001B[49m)])  \u001B[38;5;66;03m# forward\u001B[39;00m\n\u001B[0;32m     23\u001B[0m check_anchor_order(m)\n\u001B[0;32m     24\u001B[0m m\u001B[38;5;241m.\u001B[39manchors \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m m\u001B[38;5;241m.\u001B[39mstride\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mTypeError\u001B[0m: zeros(): argument 'size' must be tuple of SymInts, but found element of type list at pos 2"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T12:04:18.262592300Z",
     "start_time": "2024-05-09T12:04:18.228601900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T12:04:15.582562500Z",
     "start_time": "2024-05-09T12:04:15.573594700Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
