digraph {
	graph [size="133.04999999999998,133.04999999999998"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2050419231776 [label="
 (1, 3, 80, 80, 11)" fillcolor=darkolivegreen1]
	2050419189408 [label=CloneBackward0]
	2050419189504 -> 2050419189408
	2050419189504 [label=PermuteBackward0]
	2050419189264 -> 2050419189504
	2050419189264 [label=ViewBackward0]
	2050419189552 -> 2050419189264
	2050419189552 [label=ConvolutionBackward0]
	2050419189648 -> 2050419189552
	2050419189648 [label=SiluBackward0]
	2050419189840 -> 2050419189648
	2050419189840 [label=CudnnBatchNormBackward0]
	2050419189936 -> 2050419189840
	2050419189936 [label=ConvolutionBackward0]
	2050419190176 -> 2050419189936
	2050419190176 [label=CatBackward0]
	2050419190320 -> 2050419190176
	2050419190320 [label=SiluBackward0]
	2050419190464 -> 2050419190320
	2050419190464 [label=CudnnBatchNormBackward0]
	2050419190560 -> 2050419190464
	2050419190560 [label=ConvolutionBackward0]
	2050419190752 -> 2050419190560
	2050419190752 [label=SiluBackward0]
	2050419190896 -> 2050419190752
	2050419190896 [label=CudnnBatchNormBackward0]
	2050419190128 -> 2050419190896
	2050419190128 [label=ConvolutionBackward0]
	2050419191136 -> 2050419190128
	2050419191136 [label=SiluBackward0]
	2050419191280 -> 2050419191136
	2050419191280 [label=CudnnBatchNormBackward0]
	2050419191376 -> 2050419191280
	2050419191376 [label=ConvolutionBackward0]
	2050419191568 -> 2050419191376
	2050419191568 [label=CatBackward0]
	2050419191760 -> 2050419191568
	2050419191760 [label=UpsampleNearest2DBackward1]
	2050419189312 -> 2050419191760
	2050419189312 [label=SiluBackward0]
	2050419257408 -> 2050419189312
	2050419257408 [label=CudnnBatchNormBackward0]
	2050419257600 -> 2050419257408
	2050419257600 [label=ConvolutionBackward0]
	2050419257792 -> 2050419257600
	2050419257792 [label=SiluBackward0]
	2050419257936 -> 2050419257792
	2050419257936 [label=CudnnBatchNormBackward0]
	2050419258032 -> 2050419257936
	2050419258032 [label=ConvolutionBackward0]
	2050419258224 -> 2050419258032
	2050419258224 [label=CatBackward0]
	2050419258368 -> 2050419258224
	2050419258368 [label=SiluBackward0]
	2050419258512 -> 2050419258368
	2050419258512 [label=CudnnBatchNormBackward0]
	2050419258608 -> 2050419258512
	2050419258608 [label=ConvolutionBackward0]
	2050419258800 -> 2050419258608
	2050419258800 [label=SiluBackward0]
	2050419258944 -> 2050419258800
	2050419258944 [label=CudnnBatchNormBackward0]
	2050419259040 -> 2050419258944
	2050419259040 [label=ConvolutionBackward0]
	2050419259232 -> 2050419259040
	2050419259232 [label=SiluBackward0]
	2050419259376 -> 2050419259232
	2050419259376 [label=CudnnBatchNormBackward0]
	2050419259472 -> 2050419259376
	2050419259472 [label=ConvolutionBackward0]
	2050419259664 -> 2050419259472
	2050419259664 [label=CatBackward0]
	2050419259808 -> 2050419259664
	2050419259808 [label=UpsampleNearest2DBackward1]
	2050419259952 -> 2050419259808
	2050419259952 [label=SiluBackward0]
	2050419260048 -> 2050419259952
	2050419260048 [label=CudnnBatchNormBackward0]
	2050419260144 -> 2050419260048
	2050419260144 [label=ConvolutionBackward0]
	2050419260336 -> 2050419260144
	2050419260336 [label=SiluBackward0]
	2050419260480 -> 2050419260336
	2050419260480 [label=CudnnBatchNormBackward0]
	2050419260576 -> 2050419260480
	2050419260576 [label=ConvolutionBackward0]
	2050419260768 -> 2050419260576
	2050419260768 [label=CatBackward0]
	2050419260912 -> 2050419260768
	2050419260912 [label=SiluBackward0]
	2050419261152 -> 2050419260912
	2050419261152 [label=CudnnBatchNormBackward0]
	2050419261248 -> 2050419261152
	2050419261248 [label=ConvolutionBackward0]
	2050419261392 -> 2050419261248
	2050419261392 [label=SiluBackward0]
	2050419265744 -> 2050419261392
	2050419265744 [label=CudnnBatchNormBackward0]
	2050419265840 -> 2050419265744
	2050419265840 [label=ConvolutionBackward0]
	2050419266032 -> 2050419265840
	2050419266032 [label=CatBackward0]
	2050419266176 -> 2050419266032
	2050419266176 [label=AddBackward0]
	2050419266320 -> 2050419266176
	2050419266320 [label=SiluBackward0]
	2050419266464 -> 2050419266320
	2050419266464 [label=CudnnBatchNormBackward0]
	2050419266560 -> 2050419266464
	2050419266560 [label=ConvolutionBackward0]
	2050419266752 -> 2050419266560
	2050419266752 [label=SiluBackward0]
	2050419266896 -> 2050419266752
	2050419266896 [label=CudnnBatchNormBackward0]
	2050419266992 -> 2050419266896
	2050419266992 [label=ConvolutionBackward0]
	2050419259760 -> 2050419266992
	2050419259760 [label=SiluBackward0]
	2050419267280 -> 2050419259760
	2050419267280 [label=CudnnBatchNormBackward0]
	2050419267376 -> 2050419267280
	2050419267376 [label=ConvolutionBackward0]
	2050419267568 -> 2050419267376
	2050419267568 [label=CatBackward0]
	2050419267712 -> 2050419267568
	2050419267712 [label=AddBackward0]
	2050419267856 -> 2050419267712
	2050419267856 [label=AddBackward0]
	2050419268000 -> 2050419267856
	2050419268000 [label=AddBackward0]
	2050419268144 -> 2050419268000
	2050419268144 [label=SiluBackward0]
	2050419268288 -> 2050419268144
	2050419268288 [label=CudnnBatchNormBackward0]
	2050419268384 -> 2050419268288
	2050419268384 [label=ConvolutionBackward0]
	2050419268576 -> 2050419268384
	2050419268576 [label=SiluBackward0]
	2050419268720 -> 2050419268576
	2050419268720 [label=CudnnBatchNormBackward0]
	2050419268816 -> 2050419268720
	2050419268816 [label=ConvolutionBackward0]
	2050419191712 -> 2050419268816
	2050419191712 [label=SiluBackward0]
	2050419269104 -> 2050419191712
	2050419269104 [label=CudnnBatchNormBackward0]
	2050419269200 -> 2050419269104
	2050419269200 [label=ConvolutionBackward0]
	2050419269392 -> 2050419269200
	2050419269392 [label=CatBackward0]
	2050419269536 -> 2050419269392
	2050419269536 [label=AddBackward0]
	2050419269584 -> 2050419269536
	2050419269584 [label=AddBackward0]
	2050419278080 -> 2050419269584
	2050419278080 [label=SiluBackward0]
	2050419278224 -> 2050419278080
	2050419278224 [label=CudnnBatchNormBackward0]
	2050419278320 -> 2050419278224
	2050419278320 [label=ConvolutionBackward0]
	2050419278512 -> 2050419278320
	2050419278512 [label=SiluBackward0]
	2050419278656 -> 2050419278512
	2050419278656 [label=CudnnBatchNormBackward0]
	2050419278752 -> 2050419278656
	2050419278752 [label=ConvolutionBackward0]
	2050419278944 -> 2050419278752
	2050419278944 [label=SiluBackward0]
	2050419279088 -> 2050419278944
	2050419279088 [label=CudnnBatchNormBackward0]
	2050419279184 -> 2050419279088
	2050419279184 [label=ConvolutionBackward0]
	2050419279376 -> 2050419279184
	2050419279376 [label=CatBackward0]
	2050419279520 -> 2050419279376
	2050419279520 [label=AddBackward0]
	2050419279664 -> 2050419279520
	2050419279664 [label=SiluBackward0]
	2050419279808 -> 2050419279664
	2050419279808 [label=CudnnBatchNormBackward0]
	2050419279904 -> 2050419279808
	2050419279904 [label=ConvolutionBackward0]
	2050419280096 -> 2050419279904
	2050419280096 [label=SiluBackward0]
	2050419280240 -> 2050419280096
	2050419280240 [label=CudnnBatchNormBackward0]
	2050419280336 -> 2050419280240
	2050419280336 [label=ConvolutionBackward0]
	2050419280528 -> 2050419280336
	2050419280528 [label=SiluBackward0]
	2050419280672 -> 2050419280528
	2050419280672 [label=CudnnBatchNormBackward0]
	2050419280768 -> 2050419280672
	2050419280768 [label=ConvolutionBackward0]
	2050419280960 -> 2050419280768
	2050418416032 [label="model.0.conv.weight
 (32, 3, 6, 6)" fillcolor=lightblue]
	2050418416032 -> 2050419280960
	2050419280960 [label=AccumulateGrad]
	2050419280720 -> 2050419280672
	2050418415072 [label="model.0.bn.weight
 (32)" fillcolor=lightblue]
	2050418415072 -> 2050419280720
	2050419280720 [label=AccumulateGrad]
	2050419280576 -> 2050419280672
	2050418414672 [label="model.0.bn.bias
 (32)" fillcolor=lightblue]
	2050418414672 -> 2050419280576
	2050419280576 [label=AccumulateGrad]
	2050419280480 -> 2050419280336
	2050418416272 [label="model.1.conv.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	2050418416272 -> 2050419280480
	2050419280480 [label=AccumulateGrad]
	2050419280288 -> 2050419280240
	2050418415952 [label="model.1.bn.weight
 (64)" fillcolor=lightblue]
	2050418415952 -> 2050419280288
	2050419280288 [label=AccumulateGrad]
	2050419280144 -> 2050419280240
	2050418416192 [label="model.1.bn.bias
 (64)" fillcolor=lightblue]
	2050418416192 -> 2050419280144
	2050419280144 [label=AccumulateGrad]
	2050419280048 -> 2050419279904
	2050418415472 [label="model.2.cv1.conv.weight
 (32, 64, 1, 1)" fillcolor=lightblue]
	2050418415472 -> 2050419280048
	2050419280048 [label=AccumulateGrad]
	2050419279856 -> 2050419279808
	2050418416112 [label="model.2.cv1.bn.weight
 (32)" fillcolor=lightblue]
	2050418416112 -> 2050419279856
	2050419279856 [label=AccumulateGrad]
	2050419279712 -> 2050419279808
	2050418416672 [label="model.2.cv1.bn.bias
 (32)" fillcolor=lightblue]
	2050418416672 -> 2050419279712
	2050419279712 [label=AccumulateGrad]
	2050419279616 -> 2050419279520
	2050419279616 [label=SiluBackward0]
	2050419280000 -> 2050419279616
	2050419280000 [label=CudnnBatchNormBackward0]
	2050419280384 -> 2050419280000
	2050419280384 [label=ConvolutionBackward0]
	2050419280624 -> 2050419280384
	2050419280624 [label=SiluBackward0]
	2050419280864 -> 2050419280624
	2050419280864 [label=CudnnBatchNormBackward0]
	2050419281152 -> 2050419280864
	2050419281152 [label=ConvolutionBackward0]
	2050419279664 -> 2050419281152
	2050419281344 -> 2050419281152
	2050418577712 [label="model.2.m.0.cv1.conv.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	2050418577712 -> 2050419281344
	2050419281344 [label=AccumulateGrad]
	2050419281104 -> 2050419280864
	2050418577632 [label="model.2.m.0.cv1.bn.weight
 (32)" fillcolor=lightblue]
	2050418577632 -> 2050419281104
	2050419281104 [label=AccumulateGrad]
	2050419281056 -> 2050419280864
	2050418577792 [label="model.2.m.0.cv1.bn.bias
 (32)" fillcolor=lightblue]
	2050418577792 -> 2050419281056
	2050419281056 [label=AccumulateGrad]
	2050419280816 -> 2050419280384
	2050418578272 [label="model.2.m.0.cv2.conv.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	2050418578272 -> 2050419280816
	2050419280816 [label=AccumulateGrad]
	2050419280432 -> 2050419280000
	2050418578192 [label="model.2.m.0.cv2.bn.weight
 (32)" fillcolor=lightblue]
	2050418578192 -> 2050419280432
	2050419280432 [label=AccumulateGrad]
	2050419279760 -> 2050419280000
	2050418578352 [label="model.2.m.0.cv2.bn.bias
 (32)" fillcolor=lightblue]
	2050418578352 -> 2050419279760
	2050419279760 [label=AccumulateGrad]
	2050419279472 -> 2050419279376
	2050419279472 [label=SiluBackward0]
	2050419280192 -> 2050419279472
	2050419280192 [label=CudnnBatchNormBackward0]
	2050419281296 -> 2050419280192
	2050419281296 [label=ConvolutionBackward0]
	2050419280096 -> 2050419281296
	2050419281392 -> 2050419281296
	2050418414352 [label="model.2.cv2.conv.weight
 (32, 64, 1, 1)" fillcolor=lightblue]
	2050418414352 -> 2050419281392
	2050419281392 [label=AccumulateGrad]
	2050419280912 -> 2050419280192
	2050418417552 [label="model.2.cv2.bn.weight
 (32)" fillcolor=lightblue]
	2050418417552 -> 2050419280912
	2050419280912 [label=AccumulateGrad]
	2050419279568 -> 2050419280192
	2050418417152 [label="model.2.cv2.bn.bias
 (32)" fillcolor=lightblue]
	2050418417152 -> 2050419279568
	2050419279568 [label=AccumulateGrad]
	2050419279328 -> 2050419279184
	2050418416832 [label="model.2.cv3.conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2050418416832 -> 2050419279328
	2050419279328 [label=AccumulateGrad]
	2050419279136 -> 2050419279088
	2050418415792 [label="model.2.cv3.bn.weight
 (64)" fillcolor=lightblue]
	2050418415792 -> 2050419279136
	2050419279136 [label=AccumulateGrad]
	2050419278992 -> 2050419279088
	2050418415232 [label="model.2.cv3.bn.bias
 (64)" fillcolor=lightblue]
	2050418415232 -> 2050419278992
	2050419278992 [label=AccumulateGrad]
	2050419278896 -> 2050419278752
	2050418578912 [label="model.3.conv.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	2050418578912 -> 2050419278896
	2050419278896 [label=AccumulateGrad]
	2050419278704 -> 2050419278656
	2050418578832 [label="model.3.bn.weight
 (128)" fillcolor=lightblue]
	2050418578832 -> 2050419278704
	2050419278704 [label=AccumulateGrad]
	2050419278560 -> 2050419278656
	2050418578992 [label="model.3.bn.bias
 (128)" fillcolor=lightblue]
	2050418578992 -> 2050419278560
	2050419278560 [label=AccumulateGrad]
	2050419278464 -> 2050419278320
	2050418579552 [label="model.4.cv1.conv.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	2050418579552 -> 2050419278464
	2050419278464 [label=AccumulateGrad]
	2050419278272 -> 2050419278224
	2050418579392 [label="model.4.cv1.bn.weight
 (64)" fillcolor=lightblue]
	2050418579392 -> 2050419278272
	2050419278272 [label=AccumulateGrad]
	2050419278128 -> 2050419278224
	2050418579632 [label="model.4.cv1.bn.bias
 (64)" fillcolor=lightblue]
	2050418579632 -> 2050419278128
	2050419278128 [label=AccumulateGrad]
	2050419278032 -> 2050419269584
	2050419278032 [label=SiluBackward0]
	2050419278416 -> 2050419278032
	2050419278416 [label=CudnnBatchNormBackward0]
	2050419278800 -> 2050419278416
	2050419278800 [label=ConvolutionBackward0]
	2050419279040 -> 2050419278800
	2050419279040 [label=SiluBackward0]
	2050419279424 -> 2050419279040
	2050419279424 [label=CudnnBatchNormBackward0]
	2050419281488 -> 2050419279424
	2050419281488 [label=ConvolutionBackward0]
	2050419278080 -> 2050419281488
	2050419281584 -> 2050419281488
	2050418581232 [label="model.4.m.0.cv1.conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2050418581232 -> 2050419281584
	2050419281584 [label=AccumulateGrad]
	2050419281440 -> 2050419279424
	2050418581152 [label="model.4.m.0.cv1.bn.weight
 (64)" fillcolor=lightblue]
	2050418581152 -> 2050419281440
	2050419281440 [label=AccumulateGrad]
	2050419281200 -> 2050419279424
	2050418581312 [label="model.4.m.0.cv1.bn.bias
 (64)" fillcolor=lightblue]
	2050418581312 -> 2050419281200
	2050419281200 [label=AccumulateGrad]
	2050419279232 -> 2050419278800
	2050418676096 [label="model.4.m.0.cv2.conv.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2050418676096 -> 2050419279232
	2050419279232 [label=AccumulateGrad]
	2050419278848 -> 2050419278416
	2050418676016 [label="model.4.m.0.cv2.bn.weight
 (64)" fillcolor=lightblue]
	2050418676016 -> 2050419278848
	2050419278848 [label=AccumulateGrad]
	2050419278176 -> 2050419278416
	2050418676176 [label="model.4.m.0.cv2.bn.bias
 (64)" fillcolor=lightblue]
	2050418676176 -> 2050419278176
	2050419278176 [label=AccumulateGrad]
	2050419277888 -> 2050419269536
	2050419277888 [label=SiluBackward0]
	2050419278608 -> 2050419277888
	2050419278608 [label=CudnnBatchNormBackward0]
	2050419281536 -> 2050419278608
	2050419281536 [label=ConvolutionBackward0]
	2050419281632 -> 2050419281536
	2050419281632 [label=SiluBackward0]
	2050419281776 -> 2050419281632
	2050419281776 [label=CudnnBatchNormBackward0]
	2050419281872 -> 2050419281776
	2050419281872 [label=ConvolutionBackward0]
	2050419269584 -> 2050419281872
	2050419298512 -> 2050419281872
	2050418676656 [label="model.4.m.1.cv1.conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2050418676656 -> 2050419298512
	2050419298512 [label=AccumulateGrad]
	2050419281824 -> 2050419281776
	2050418676576 [label="model.4.m.1.cv1.bn.weight
 (64)" fillcolor=lightblue]
	2050418676576 -> 2050419281824
	2050419281824 [label=AccumulateGrad]
	2050419281008 -> 2050419281776
	2050418676736 [label="model.4.m.1.cv1.bn.bias
 (64)" fillcolor=lightblue]
	2050418676736 -> 2050419281008
	2050419281008 [label=AccumulateGrad]
	2050419281680 -> 2050419281536
	2050418677216 [label="model.4.m.1.cv2.conv.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2050418677216 -> 2050419281680
	2050419281680 [label=AccumulateGrad]
	2050419279280 -> 2050419278608
	2050418677136 [label="model.4.m.1.cv2.bn.weight
 (64)" fillcolor=lightblue]
	2050418677136 -> 2050419279280
	2050419279280 [label=AccumulateGrad]
	2050419277984 -> 2050419278608
	2050418677296 [label="model.4.m.1.cv2.bn.bias
 (64)" fillcolor=lightblue]
	2050418677296 -> 2050419277984
	2050419277984 [label=AccumulateGrad]
	2050419269488 -> 2050419269392
	2050419269488 [label=SiluBackward0]
	2050419281248 -> 2050419269488
	2050419281248 [label=CudnnBatchNormBackward0]
	2050419281728 -> 2050419281248
	2050419281728 [label=ConvolutionBackward0]
	2050419278512 -> 2050419281728
	2050419298560 -> 2050419281728
	2050418580112 [label="model.4.cv2.conv.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	2050418580112 -> 2050419298560
	2050419298560 [label=AccumulateGrad]
	2050419279952 -> 2050419281248
	2050418580032 [label="model.4.cv2.bn.weight
 (64)" fillcolor=lightblue]
	2050418580032 -> 2050419279952
	2050419279952 [label=AccumulateGrad]
	2050419277936 -> 2050419281248
	2050418580192 [label="model.4.cv2.bn.bias
 (64)" fillcolor=lightblue]
	2050418580192 -> 2050419277936
	2050419277936 [label=AccumulateGrad]
	2050419269344 -> 2050419269200
	2050418580672 [label="model.4.cv3.conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2050418580672 -> 2050419269344
	2050419269344 [label=AccumulateGrad]
	2050419269152 -> 2050419269104
	2050418580592 [label="model.4.cv3.bn.weight
 (128)" fillcolor=lightblue]
	2050418580592 -> 2050419269152
	2050419269152 [label=AccumulateGrad]
	2050419268912 -> 2050419269104
	2050418580752 [label="model.4.cv3.bn.bias
 (128)" fillcolor=lightblue]
	2050418580752 -> 2050419268912
	2050419268912 [label=AccumulateGrad]
	2050419269008 -> 2050419268816
	2050418677856 [label="model.5.conv.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	2050418677856 -> 2050419269008
	2050419269008 [label=AccumulateGrad]
	2050419268768 -> 2050419268720
	2050418677696 [label="model.5.bn.weight
 (256)" fillcolor=lightblue]
	2050418677696 -> 2050419268768
	2050419268768 [label=AccumulateGrad]
	2050419268624 -> 2050419268720
	2050418677936 [label="model.5.bn.bias
 (256)" fillcolor=lightblue]
	2050418677936 -> 2050419268624
	2050419268624 [label=AccumulateGrad]
	2050419268528 -> 2050419268384
	2050418678496 [label="model.6.cv1.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2050418678496 -> 2050419268528
	2050419268528 [label=AccumulateGrad]
	2050419268336 -> 2050419268288
	2050418678336 [label="model.6.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2050418678336 -> 2050419268336
	2050419268336 [label=AccumulateGrad]
	2050419268192 -> 2050419268288
	2050418678576 [label="model.6.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2050418678576 -> 2050419268192
	2050419268192 [label=AccumulateGrad]
	2050419268096 -> 2050419268000
	2050419268096 [label=SiluBackward0]
	2050419278368 -> 2050419268096
	2050419278368 [label=CudnnBatchNormBackward0]
	2050419268864 -> 2050419278368
	2050419268864 [label=ConvolutionBackward0]
	2050419269056 -> 2050419268864
	2050419269056 [label=SiluBackward0]
	2050419269440 -> 2050419269056
	2050419269440 [label=CudnnBatchNormBackward0]
	2050419298416 -> 2050419269440
	2050419298416 [label=ConvolutionBackward0]
	2050419268144 -> 2050419298416
	2050419298800 -> 2050419298416
	2050418754000 [label="model.6.m.0.cv1.conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2050418754000 -> 2050419298800
	2050419298800 [label=AccumulateGrad]
	2050419298656 -> 2050419269440
	2050418753920 [label="model.6.m.0.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2050418753920 -> 2050419298656
	2050419298656 [label=AccumulateGrad]
	2050419298608 -> 2050419269440
	2050418754080 [label="model.6.m.0.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2050418754080 -> 2050419298608
	2050419298608 [label=AccumulateGrad]
	2050419269248 -> 2050419268864
	2050418754560 [label="model.6.m.0.cv2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2050418754560 -> 2050419269248
	2050419269248 [label=AccumulateGrad]
	2050419268480 -> 2050419278368
	2050418754480 [label="model.6.m.0.cv2.bn.weight
 (128)" fillcolor=lightblue]
	2050418754480 -> 2050419268480
	2050419268480 [label=AccumulateGrad]
	2050419268240 -> 2050419278368
	2050418754640 [label="model.6.m.0.cv2.bn.bias
 (128)" fillcolor=lightblue]
	2050418754640 -> 2050419268240
	2050419268240 [label=AccumulateGrad]
	2050419267952 -> 2050419267856
	2050419267952 [label=SiluBackward0]
	2050419268672 -> 2050419267952
	2050419268672 [label=CudnnBatchNormBackward0]
	2050419269296 -> 2050419268672
	2050419269296 [label=ConvolutionBackward0]
	2050419298848 -> 2050419269296
	2050419298848 [label=SiluBackward0]
	2050419298992 -> 2050419298848
	2050419298992 [label=CudnnBatchNormBackward0]
	2050419299088 -> 2050419298992
	2050419299088 [label=ConvolutionBackward0]
	2050419268000 -> 2050419299088
	2050419299280 -> 2050419299088
	2050418755120 [label="model.6.m.1.cv1.conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2050418755120 -> 2050419299280
	2050419299280 [label=AccumulateGrad]
	2050419299040 -> 2050419298992
	2050418755040 [label="model.6.m.1.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2050418755040 -> 2050419299040
	2050419299040 [label=AccumulateGrad]
	2050419298704 -> 2050419298992
	2050418755200 [label="model.6.m.1.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2050418755200 -> 2050419298704
	2050419298704 [label=AccumulateGrad]
	2050419298896 -> 2050419269296
	2050418755680 [label="model.6.m.1.cv2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2050418755680 -> 2050419298896
	2050419298896 [label=AccumulateGrad]
	2050419268960 -> 2050419268672
	2050418755600 [label="model.6.m.1.cv2.bn.weight
 (128)" fillcolor=lightblue]
	2050418755600 -> 2050419268960
	2050419268960 [label=AccumulateGrad]
	2050419268048 -> 2050419268672
	2050418755760 [label="model.6.m.1.cv2.bn.bias
 (128)" fillcolor=lightblue]
	2050418755760 -> 2050419268048
	2050419268048 [label=AccumulateGrad]
	2050419267808 -> 2050419267712
	2050419267808 [label=SiluBackward0]
	2050419268432 -> 2050419267808
	2050419268432 [label=CudnnBatchNormBackward0]
	2050419299232 -> 2050419268432
	2050419299232 [label=ConvolutionBackward0]
	2050419299328 -> 2050419299232
	2050419299328 [label=SiluBackward0]
	2050419299472 -> 2050419299328
	2050419299472 [label=CudnnBatchNormBackward0]
	2050419299568 -> 2050419299472
	2050419299568 [label=ConvolutionBackward0]
	2050419267856 -> 2050419299568
	2050419299760 -> 2050419299568
	2050418756240 [label="model.6.m.2.cv1.conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2050418756240 -> 2050419299760
	2050419299760 [label=AccumulateGrad]
	2050419299520 -> 2050419299472
	2050418756160 [label="model.6.m.2.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2050418756160 -> 2050419299520
	2050419299520 [label=AccumulateGrad]
	2050419299184 -> 2050419299472
	2050418756320 [label="model.6.m.2.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2050418756320 -> 2050419299184
	2050419299184 [label=AccumulateGrad]
	2050419299376 -> 2050419299232
	2050418756800 [label="model.6.m.2.cv2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2050418756800 -> 2050419299376
	2050419299376 [label=AccumulateGrad]
	2050419298368 -> 2050419268432
	2050418756720 [label="model.6.m.2.cv2.bn.weight
 (128)" fillcolor=lightblue]
	2050418756720 -> 2050419298368
	2050419298368 [label=AccumulateGrad]
	2050419298752 -> 2050419268432
	2050418756880 [label="model.6.m.2.cv2.bn.bias
 (128)" fillcolor=lightblue]
	2050418756880 -> 2050419298752
	2050419298752 [label=AccumulateGrad]
	2050419267664 -> 2050419267568
	2050419267664 [label=SiluBackward0]
	2050419267904 -> 2050419267664
	2050419267904 [label=CudnnBatchNormBackward0]
	2050419299712 -> 2050419267904
	2050419299712 [label=ConvolutionBackward0]
	2050419268576 -> 2050419299712
	2050419299808 -> 2050419299712
	2050418679056 [label="model.6.cv2.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2050418679056 -> 2050419299808
	2050419299808 [label=AccumulateGrad]
	2050419298944 -> 2050419267904
	2050418678976 [label="model.6.cv2.bn.weight
 (128)" fillcolor=lightblue]
	2050418678976 -> 2050419298944
	2050419298944 [label=AccumulateGrad]
	2050419299136 -> 2050419267904
	2050418679136 [label="model.6.cv2.bn.bias
 (128)" fillcolor=lightblue]
	2050418679136 -> 2050419299136
	2050419299136 [label=AccumulateGrad]
	2050419267520 -> 2050419267376
	2050418679616 [label="model.6.cv3.conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	2050418679616 -> 2050419267520
	2050419267520 [label=AccumulateGrad]
	2050419267328 -> 2050419267280
	2050418679536 [label="model.6.cv3.bn.weight
 (256)" fillcolor=lightblue]
	2050418679536 -> 2050419267328
	2050419267328 [label=AccumulateGrad]
	2050419267088 -> 2050419267280
	2050418679696 [label="model.6.cv3.bn.bias
 (256)" fillcolor=lightblue]
	2050418679696 -> 2050419267088
	2050419267088 [label=AccumulateGrad]
	2050419267184 -> 2050419266992
	2050418757440 [label="model.7.conv.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	2050418757440 -> 2050419267184
	2050419267184 [label=AccumulateGrad]
	2050419266944 -> 2050419266896
	2050418757280 [label="model.7.bn.weight
 (512)" fillcolor=lightblue]
	2050418757280 -> 2050419266944
	2050419266944 [label=AccumulateGrad]
	2050419266800 -> 2050419266896
	2050418757520 [label="model.7.bn.bias
 (512)" fillcolor=lightblue]
	2050418757520 -> 2050419266800
	2050419266800 [label=AccumulateGrad]
	2050419266704 -> 2050419266560
	2050526319136 [label="model.8.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2050526319136 -> 2050419266704
	2050419266704 [label=AccumulateGrad]
	2050419266512 -> 2050419266464
	2050526318976 [label="model.8.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2050526318976 -> 2050419266512
	2050419266512 [label=AccumulateGrad]
	2050419266368 -> 2050419266464
	2050526319216 [label="model.8.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2050526319216 -> 2050419266368
	2050419266368 [label=AccumulateGrad]
	2050419266272 -> 2050419266176
	2050419266272 [label=SiluBackward0]
	2050419266656 -> 2050419266272
	2050419266656 [label=CudnnBatchNormBackward0]
	2050419267040 -> 2050419266656
	2050419267040 [label=ConvolutionBackward0]
	2050419267232 -> 2050419267040
	2050419267232 [label=SiluBackward0]
	2050419267616 -> 2050419267232
	2050419267616 [label=CudnnBatchNormBackward0]
	2050419299904 -> 2050419267616
	2050419299904 [label=ConvolutionBackward0]
	2050419266320 -> 2050419299904
	2050419300000 -> 2050419299904
	2050526320816 [label="model.8.m.0.cv1.conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	2050526320816 -> 2050419300000
	2050419300000 [label=AccumulateGrad]
	2050419299856 -> 2050419267616
	2050526320736 [label="model.8.m.0.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2050526320736 -> 2050419299856
	2050419299856 [label=AccumulateGrad]
	2050419299616 -> 2050419267616
	2050526320896 [label="model.8.m.0.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2050526320896 -> 2050419299616
	2050419299616 [label=AccumulateGrad]
	2050419267424 -> 2050419267040
	2050526321376 [label="model.8.m.0.cv2.conv.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	2050526321376 -> 2050419267424
	2050419267424 [label=AccumulateGrad]
	2050419267136 -> 2050419266656
	2050526321296 [label="model.8.m.0.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2050526321296 -> 2050419267136
	2050419267136 [label=AccumulateGrad]
	2050419266416 -> 2050419266656
	2050526321456 [label="model.8.m.0.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2050526321456 -> 2050419266416
	2050419266416 [label=AccumulateGrad]
	2050419266128 -> 2050419266032
	2050419266128 [label=SiluBackward0]
	2050419266848 -> 2050419266128
	2050419266848 [label=CudnnBatchNormBackward0]
	2050419267760 -> 2050419266848
	2050419267760 [label=ConvolutionBackward0]
	2050419266752 -> 2050419267760
	2050419300048 -> 2050419267760
	2050526319696 [label="model.8.cv2.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2050526319696 -> 2050419300048
	2050419300048 [label=AccumulateGrad]
	2050419267472 -> 2050419266848
	2050526319616 [label="model.8.cv2.bn.weight
 (256)" fillcolor=lightblue]
	2050526319616 -> 2050419267472
	2050419267472 [label=AccumulateGrad]
	2050419266224 -> 2050419266848
	2050526319776 [label="model.8.cv2.bn.bias
 (256)" fillcolor=lightblue]
	2050526319776 -> 2050419266224
	2050419266224 [label=AccumulateGrad]
	2050419265984 -> 2050419265840
	2050526320256 [label="model.8.cv3.conv.weight
 (512, 512, 1, 1)" fillcolor=lightblue]
	2050526320256 -> 2050419265984
	2050419265984 [label=AccumulateGrad]
	2050419265792 -> 2050419265744
	2050526320176 [label="model.8.cv3.bn.weight
 (512)" fillcolor=lightblue]
	2050526320176 -> 2050419265792
	2050419265792 [label=AccumulateGrad]
	2050419265648 -> 2050419265744
	2050526320336 [label="model.8.cv3.bn.bias
 (512)" fillcolor=lightblue]
	2050526320336 -> 2050419265648
	2050419265648 [label=AccumulateGrad]
	2050419261344 -> 2050419261248
	2050526322016 [label="model.9.cv1.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2050526322016 -> 2050419261344
	2050419261344 [label=AccumulateGrad]
	2050419261200 -> 2050419261152
	2050526321856 [label="model.9.cv1.bn.weight
 (256)" fillcolor=lightblue]
	2050526321856 -> 2050419261200
	2050419261200 [label=AccumulateGrad]
	2050419261056 -> 2050419261152
	2050526322096 [label="model.9.cv1.bn.bias
 (256)" fillcolor=lightblue]
	2050526322096 -> 2050419261056
	2050419261056 [label=AccumulateGrad]
	2050419260864 -> 2050419260768
	2050419260864 [label=MaxPool2DWithIndicesBackward0]
	2050419260912 -> 2050419260864
	2050419260816 -> 2050419260768
	2050419260816 [label=MaxPool2DWithIndicesBackward0]
	2050419260864 -> 2050419260816
	2050419260960 -> 2050419260768
	2050419260960 [label=MaxPool2DWithIndicesBackward0]
	2050419260816 -> 2050419260960
	2050419260720 -> 2050419260576
	2050526322576 [label="model.9.cv2.conv.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	2050526322576 -> 2050419260720
	2050419260720 [label=AccumulateGrad]
	2050419260528 -> 2050419260480
	2050526322496 [label="model.9.cv2.bn.weight
 (512)" fillcolor=lightblue]
	2050526322496 -> 2050419260528
	2050419260528 [label=AccumulateGrad]
	2050419260384 -> 2050419260480
	2050526408768 [label="model.9.cv2.bn.bias
 (512)" fillcolor=lightblue]
	2050526408768 -> 2050419260384
	2050419260384 [label=AccumulateGrad]
	2050419260288 -> 2050419260144
	2050526409328 [label="model.10.conv.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	2050526409328 -> 2050419260288
	2050419260288 [label=AccumulateGrad]
	2050419260096 -> 2050419260048
	2050526409168 [label="model.10.bn.weight
 (256)" fillcolor=lightblue]
	2050526409168 -> 2050419260096
	2050419260096 [label=AccumulateGrad]
	2050419259856 -> 2050419260048
	2050526409408 [label="model.10.bn.bias
 (256)" fillcolor=lightblue]
	2050526409408 -> 2050419259856
	2050419259856 [label=AccumulateGrad]
	2050419259760 -> 2050419259664
	2050419259616 -> 2050419259472
	2050526410048 [label="model.13.cv1.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2050526410048 -> 2050419259616
	2050419259616 [label=AccumulateGrad]
	2050419259424 -> 2050419259376
	2050526409968 [label="model.13.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2050526409968 -> 2050419259424
	2050419259424 [label=AccumulateGrad]
	2050419259280 -> 2050419259376
	2050526410128 [label="model.13.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2050526410128 -> 2050419259280
	2050419259280 [label=AccumulateGrad]
	2050419259184 -> 2050419259040
	2050526411808 [label="model.13.m.0.cv1.conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2050526411808 -> 2050419259184
	2050419259184 [label=AccumulateGrad]
	2050419258992 -> 2050419258944
	2050526411728 [label="model.13.m.0.cv1.bn.weight
 (128)" fillcolor=lightblue]
	2050526411728 -> 2050419258992
	2050419258992 [label=AccumulateGrad]
	2050419258848 -> 2050419258944
	2050526411888 [label="model.13.m.0.cv1.bn.bias
 (128)" fillcolor=lightblue]
	2050526411888 -> 2050419258848
	2050419258848 [label=AccumulateGrad]
	2050419258752 -> 2050419258608
	2050526412368 [label="model.13.m.0.cv2.conv.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	2050526412368 -> 2050419258752
	2050419258752 [label=AccumulateGrad]
	2050419258560 -> 2050419258512
	2050526412288 [label="model.13.m.0.cv2.bn.weight
 (128)" fillcolor=lightblue]
	2050526412288 -> 2050419258560
	2050419258560 [label=AccumulateGrad]
	2050419258416 -> 2050419258512
	2050526412448 [label="model.13.m.0.cv2.bn.bias
 (128)" fillcolor=lightblue]
	2050526412448 -> 2050419258416
	2050419258416 [label=AccumulateGrad]
	2050419258320 -> 2050419258224
	2050419258320 [label=SiluBackward0]
	2050419258704 -> 2050419258320
	2050419258704 [label=CudnnBatchNormBackward0]
	2050419259088 -> 2050419258704
	2050419259088 [label=ConvolutionBackward0]
	2050419259664 -> 2050419259088
	2050419259328 -> 2050419259088
	2050526410608 [label="model.13.cv2.conv.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	2050526410608 -> 2050419259328
	2050419259328 [label=AccumulateGrad]
	2050419259136 -> 2050419258704
	2050526410528 [label="model.13.cv2.bn.weight
 (128)" fillcolor=lightblue]
	2050526410528 -> 2050419259136
	2050419259136 [label=AccumulateGrad]
	2050419258464 -> 2050419258704
	2050526410688 [label="model.13.cv2.bn.bias
 (128)" fillcolor=lightblue]
	2050526410688 -> 2050419258464
	2050419258464 [label=AccumulateGrad]
	2050419258176 -> 2050419258032
	2050526411168 [label="model.13.cv3.conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	2050526411168 -> 2050419258176
	2050419258176 [label=AccumulateGrad]
	2050419257984 -> 2050419257936
	2050526411088 [label="model.13.cv3.bn.weight
 (256)" fillcolor=lightblue]
	2050526411088 -> 2050419257984
	2050419257984 [label=AccumulateGrad]
	2050419257840 -> 2050419257936
	2050526411248 [label="model.13.cv3.bn.bias
 (256)" fillcolor=lightblue]
	2050526411248 -> 2050419257840
	2050419257840 [label=AccumulateGrad]
	2050419257744 -> 2050419257600
	2050526486832 [label="model.14.conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	2050526486832 -> 2050419257744
	2050419257744 [label=AccumulateGrad]
	2050419257552 -> 2050419257408
	2050526486672 [label="model.14.bn.weight
 (128)" fillcolor=lightblue]
	2050526486672 -> 2050419257552
	2050419257552 [label=AccumulateGrad]
	2050419257504 -> 2050419257408
	2050526486912 [label="model.14.bn.bias
 (128)" fillcolor=lightblue]
	2050526486912 -> 2050419257504
	2050419257504 [label=AccumulateGrad]
	2050419191712 -> 2050419191568
	2050419191520 -> 2050419191376
	2050526487552 [label="model.17.cv1.conv.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2050526487552 -> 2050419191520
	2050419191520 [label=AccumulateGrad]
	2050419191328 -> 2050419191280
	2050526487472 [label="model.17.cv1.bn.weight
 (64)" fillcolor=lightblue]
	2050526487472 -> 2050419191328
	2050419191328 [label=AccumulateGrad]
	2050419191184 -> 2050419191280
	2050526487632 [label="model.17.cv1.bn.bias
 (64)" fillcolor=lightblue]
	2050526487632 -> 2050419191184
	2050419191184 [label=AccumulateGrad]
	2050419191088 -> 2050419190128
	2050526489232 [label="model.17.m.0.cv1.conv.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	2050526489232 -> 2050419191088
	2050419191088 [label=AccumulateGrad]
	2050419190944 -> 2050419190896
	2050526489152 [label="model.17.m.0.cv1.bn.weight
 (64)" fillcolor=lightblue]
	2050526489152 -> 2050419190944
	2050419190944 [label=AccumulateGrad]
	2050419190800 -> 2050419190896
	2050526489312 [label="model.17.m.0.cv1.bn.bias
 (64)" fillcolor=lightblue]
	2050526489312 -> 2050419190800
	2050419190800 [label=AccumulateGrad]
	2050419190704 -> 2050419190560
	2050526489792 [label="model.17.m.0.cv2.conv.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	2050526489792 -> 2050419190704
	2050419190704 [label=AccumulateGrad]
	2050419190512 -> 2050419190464
	2050526489712 [label="model.17.m.0.cv2.bn.weight
 (64)" fillcolor=lightblue]
	2050526489712 -> 2050419190512
	2050419190512 [label=AccumulateGrad]
	2050419190368 -> 2050419190464
	2050526489872 [label="model.17.m.0.cv2.bn.bias
 (64)" fillcolor=lightblue]
	2050526489872 -> 2050419190368
	2050419190368 [label=AccumulateGrad]
	2050419190272 -> 2050419190176
	2050419190272 [label=SiluBackward0]
	2050419190656 -> 2050419190272
	2050419190656 [label=CudnnBatchNormBackward0]
	2050419190992 -> 2050419190656
	2050419190992 [label=ConvolutionBackward0]
	2050419191568 -> 2050419190992
	2050419191232 -> 2050419190992
	2050526488112 [label="model.17.cv2.conv.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	2050526488112 -> 2050419191232
	2050419191232 [label=AccumulateGrad]
	2050419191040 -> 2050419190656
	2050526488032 [label="model.17.cv2.bn.weight
 (64)" fillcolor=lightblue]
	2050526488032 -> 2050419191040
	2050419191040 [label=AccumulateGrad]
	2050419190416 -> 2050419190656
	2050526488192 [label="model.17.cv2.bn.bias
 (64)" fillcolor=lightblue]
	2050526488192 -> 2050419190416
	2050419190416 [label=AccumulateGrad]
	2050419190080 -> 2050419189936
	2050526488672 [label="model.17.cv3.conv.weight
 (128, 128, 1, 1)" fillcolor=lightblue]
	2050526488672 -> 2050419190080
	2050419190080 [label=AccumulateGrad]
	2050419189888 -> 2050419189840
	2050526488592 [label="model.17.cv3.bn.weight
 (128)" fillcolor=lightblue]
	2050526488592 -> 2050419189888
	2050419189888 [label=AccumulateGrad]
	2050419189744 -> 2050419189840
	2050526488752 [label="model.17.cv3.bn.bias
 (128)" fillcolor=lightblue]
	2050526488752 -> 2050419189744
	2050419189744 [label=AccumulateGrad]
	2050419189600 -> 2050419189552
	2050530213696 [label="model.24.m.0.weight
 (33, 128, 1, 1)" fillcolor=lightblue]
	2050530213696 -> 2050419189600
	2050419189600 [label=AccumulateGrad]
	2050419189360 -> 2050419189552
	2050530292496 [label="model.24.m.0.bias
 (33)" fillcolor=lightblue]
	2050530292496 -> 2050419189360
	2050419189360 [label=AccumulateGrad]
	2050419189408 -> 2050419231776
}
